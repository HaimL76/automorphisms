\documentclass[12pt]{article}
\makeatletter
\newcommand*{\rom}[1]{\expandafter\@slowromancap\romannumeral #1@}
\makeatother
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{tikz-cd}
\usepackage{xcolor}
\usepackage{xparse}
\usepackage{setspace}
\usepackage{xfrac}
\usepackage{yfonts}

\ExplSyntaxOn
\NewDocumentCommand{\cycle}{ O{\;} m }
 {
  (
  \alec_cycle:nn { #1 } { #2 }
  )
 }

\seq_new:N \l_alec_cycle_seq
\cs_new_protected:Npn \alec_cycle:nn #1 #2
 {
  \seq_set_split:Nnn \l_alec_cycle_seq { , } { #2 }
  \seq_use:Nn \l_alec_cycle_seq { #1 }
 }
\ExplSyntaxOff

\begin{document}
\textbf{1. The group $U_n$} \newline
\newline
\textbf{Proposition 1.1} \newline
Let $E_n=\{ E_{i,j} \}_{i<j}$ be the set of all $n \times n$ matrices, $(e_{l,k})$, \newline where $a_{l,l}=1,1 \leq l \leq n$, and $a_{i,j}=1,i<j$, and all other elements are zero. That is, $E_{i,j}$ has $1$ only on the main diagonal, and in one element, anywhere above the main diagonal. Let $A$ be any $n \times n$ matrix. Then,\newline
Multiplying $A$ by $E_{i,j}$ (from the left), $E_{i,j} \times A$, is operating as performing the elementary operation $R_i \leftarrow R_i+R_j$ on $A$
\begin{proof}
$A=(a_{l,k}),B=(b_{l,k})=E_{i_j} \times A=(e_{l,k}) \times (a_{l,k})$ \newline
$b_{l,k}=\sum_{r=1}^n e_{l,r} \cdot a_{r,k}$ \newline
For all the rows, except for row $i$, $b_{l,k}=\sum_{r=1}^n e_{l,r} \cdot a_{r,k}=0+0+\dots+e_{l,l} \cdot a_{l,k}+0+0+\dots+0+0=1 \cdot a_{l,k}=a_{l,k}$ \newline
For row $i$, $b_{i,k}=\sum_{r=1}^n e_{i,r} \cdot a_{r,k}=0+0+\dots+e_{i,i} \cdot a_{i,k}+0+0+e_{i,j} \cdot a_{j,k}+0+0+\dots+0+0=1 \cdot a_{i,k}+1 \cdot a_{j,k}=a_{i,k}+a_{j,k}$ \newline
This shows that the multiplication preserves the rows of $A$, except for row $i$, which becomes the sum of rows $i,j$
\end{proof}
\textbf{Corollary 1.2} \newline
Let $E_{i,j}=(e_{l,k}),i<j \in E_n$, Then,\newline
$E_{i,j}^{-1}=(a_{l,k})$, where $a_{l,l}=1,1 \leq l \leq n$, and $a_{i,j}=-1,i<j$, and all other elements are zero.
\begin{proof}
$(b_{l,k})=E_{i,j} \times (a_{l,k})$ \newline
Multiplying $(a_{l,k})$ by $E_{i,j}$ from the left is operating on $(a_{l,k})$ as a row addition, $R_i \leftarrow R_i+R_j$, as seen above. \newline 
For all $1 \leq k \leq n,b_{i,k}=a_{i,k}+a_{j,k}$ \newline
But, the only element in row $j$ that is not zero is $a_{j,j=1}$, so, $b_{i,j}=a_{i,j}+a_{j,j}= \newline -1+1=0$, and, for all the other columns, $a_{j,k}=0$, so $b_{i,i}=a_{i,i}+a_{j,i}=1+0=1$, and $b_{i,k}=a_{i,k}+a_{j,k}=0+0=0$, which means that $(b_{l,k})=I_n$ \newline 
Easy to verify that also $(a_{l,k}) \times E_{i,j}=I_n$, and that $(a_{l,k})$ is a unique inverse of $E_{i,j}$, since, suppose we have another inverse matrix, $M=E_{i,j}^{-1}$, then $(a_{l,k}) \times E_{i,j}=I_n=M \times E_{i,j} \Rightarrow ((a_{l,k}) \times E_{i,j}) \times M=(M \times E_{i,j}) \times M
\Rightarrow (a_{l,k}) \times E_{i,j} \times M=M \times E_{i,j} \times M
\Rightarrow (a_{l,k}) \times (E_{i,j} \times M)=M \times (E_{i,j} \times M) \Rightarrow (a_{l,k}) \times I_n=M \times I_n \Rightarrow (a_{l,k})=M$ \newline
So, $(a_{l,k})=E_{i,j}^{-1}$ is the unique inverse of $E_{i,j}$ \newline 
\end{proof}
\newpage
\textbf{Corollary 1.3} \newline
Let $E_{i,j}=(e_{l,k}),i<j \in E_n$, and $A=(a_{l,k})$ any $n \times n$ matrix. Then,\newline
$E_{i,j}^{-1}=(b_{l,k})$ operates on $A$ as the row addition $R_i \leftarrow R_i-R_j$.
\begin{proof}
As seen above, $E_{i,j}^{-1}=(b_{l,k})$ is a matrix where $b_{l,l}=1,1 \leq l \leq n$, and $b_{i,j}=-1,i<j$, and all other elements are zero. \newline
So, the multiplication $(c_{l,k})=E_{i,j}^{-1} \times A=(b_{l,k}) \times (a_{l,k})$ is exactly the same as $E_{i,j} \times A$, for all the rows except for row $i$ \newline
For row $i$, we have $c_{i,k},1 \leq k \leq n=\sum_{r=1}^n b_{i,r} \cdot a_{r,k}$ \newline
But, the only elements that are not zero, in row $i$ of $(b_{l,k})$ are $b_{i,i}=1$, and $b_{i,j}=-1$, so, $c_{i_k}=b_{i,1} \cdot a_{1,k}+b_{i,2} \cdot a_{2,k}+\dots+b_{i,i} \cdot a_{i,k}+\dots+b_{i,j} \cdot a_{j,k}+\dots+b_{i,n-1} \cdot a_{n-1,k}+b_{i,n} \cdot a_{n,k}=0 \cdot a_{1,k}+0 \cdot a_{2,k}+\dots+1 \cdot a_{i,k}+\dots+(-1) \cdot a_{j,k}+\dots+0 \cdot a_{n-1,k}+0 \cdot a_{n,k}=0+0+\dots+a_{i,k}+\dots+(-a_{j,k})=a_{i,k}-a_{j,k}$, which shows that in the product matrix, $(c_{l,k})$, $R_i$ turns into $R_i-R_j$ \newline
\end{proof}
\textbf{Proposition 1.4} \newline
Let $E_{i,j}=(e_{l,k}),i<j \in E_n$, Then,\newline
$\forall m \in \mathbb{N},E_{i,j}^m=(a_{l,k})$, where $a_{l,l}=1,1 \leq l \leq n$, and $a_{i,j}=m,i<j$, and all other elements are zero.
\begin{proof}
By induction on $m$. \newline
For $m=2$, we observe that $E_{i,j}^2=E_{i,j} \times E_{i,j}$, which means that the multiplication from the left of $E_{i,j}$ by itself is operating on $E_{i,j}$ as the row addition $R_i \leftarrow R_i+R_j$, so, $a_{i,i}=a_{i,i}+a{j,i}=1+0=1$, and, $a_{i,j}=a_{i,j}+a_{j,j}=1+1=2$, and, all the other elements are zero (easy to verify). \newline 
So, $(a_{l,k})=E_{i,j}^2$, where $a_{l,l}=1,1 \leq l \leq n$, and $a_{i,j}=2,i<j$, and all other elements are zero. \newline
Now, we prove for $m+1$ \newline
$(a_{l,k})=E_{i,j}^{m+1}=E_{i,j} \times E_{i,j}^m$. But, from the induction assumption, $(b_{l,k})=E_{i,j}^m$, $b_{l,l}=1,1 \leq l \leq n$, and $b_{i,j}=m,i<j$, and all other elements are zero. \newline
Multiplying from the left $(b_{l,k})$ by $E_{i,j}$ is operating as the row addition $R_i \leftarrow R_i+R_j$, so, $a_{i,i}=b_{i,i}+b_{j,i}=1+0=1$, and, $a_{i,j}=b_{i,j}+b_{j,j}=m+1$, and easy to verify that all the other elements are zero, thus, we prove the induction step. \newline
\end{proof}
\end{document}